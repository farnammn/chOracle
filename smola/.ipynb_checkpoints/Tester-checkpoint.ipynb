{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Network\n",
    "from load_data import Data_Loader\n",
    "from config import setting\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config =  tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "This code is implemented from:\n",
    "Neural Survival Recommender, Amazon\n",
    "'''\n",
    "\n",
    "data_loader = Data_Loader(setting=setting)\n",
    "train_e, train_b, train_g, train_g_masked, train_mark, X_mask_train, test_e, test_b, test_g, test_g_masked, test_mark, X_mask_test = data_loader.load_data_set()\n",
    "\n",
    "setting[\"len_seq\"] = data_loader.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "network = Network(setting=setting)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "network.create_network()\n",
    "network.train_network(sess=sess, train_e=train_e, train_b=train_b, train_g=train_g, train_mark=train_mark, X_mask_train=X_mask_train, train_g_masked=train_g_masked)\n",
    "end = datetime.now()\n",
    "print(end-start)\n",
    "network.test_network(sess=sess, test_e=test_e, test_b=test_b, test_g=test_g, test_mark=test_mark, X_mask_test=X_mask_test, test_g_masked=test_g_masked)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "'''\n",
    "####################ATTENTION######################\n",
    "it seems like a good idea to list the problems we still have:\n",
    "1- we don't have the T in the datasets wich in the paper used it for adding a loss\n",
    "I commented the part wich include the third loss, wich if we have the T it can be easily added\n",
    "2- we don't have the time of the week in cleaned data in the paper it was used as a vector, although it \n",
    "can be easily added just by concating the input with d vector\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = -0.711963329787602 ,test_mse = 4.458814249013682,test_mae=0.7900764339827935, accuracy = 37.3993034362793\n",
    "test finished!\n",
    "epoch #19, train_loss = -49.3974700866902, accuracy = 3888.1500837053572\n",
    "sum_mse = 0.03888238524545064\n",
    "training finished!\n",
    "test_loss = -50.708905038759696 ,test_mse = 0.06035061076723677, accuracy = 4968.80517578125\n",
    "test finished!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.zeros((4543, 812, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ssp\n",
    "ssp.coo_matvec((4543, 812, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file_name = \"Result/lastfm_1.0.npy\"\n",
    "res = np.load(file_name).item()\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
