{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"lastfm\"\n",
    "session_length = 1.0\n",
    "dataset = np.load('../../../data/user_session_dictionary_{0}_{1}.npy'.format(dataset_name, session_length)).item()\n",
    "# dataset = np.load('data/user_session_dictionary_tianchi_seconds_7200.0.npy').item()\n",
    "max_T = 0\n",
    "n_data = 0\n",
    "for k in dataset.keys():\n",
    "    if(len(dataset[k][0]) > 10):\n",
    "        n_data += 1\n",
    "    max_T = max(max_T, len(dataset[k][0]))\n",
    "    \n",
    "T = max_T\n",
    "print(T)\n",
    "n_sampling = 90\n",
    "epsilon = 1e-12\n",
    "scale_param = 10\n",
    "n_h = 60\n",
    "n_phi_prior = 10\n",
    "n_phi_encoder = 10\n",
    "n_phi_z_decoder = 10\n",
    "n_phi_h_decoder = 10\n",
    "mu0 = 0\n",
    "sigma0 = 1.8\n",
    "n_epoch = 70\n",
    "learning_rate = 0.03\n",
    "Use_Prior = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load data\n",
    "X_T = np.zeros([n_data, T, 1])\n",
    "X_L = np.zeros([n_data, T, 1])\n",
    "X_C = np.zeros([n_data, T, 1])\n",
    "Y_T = np.zeros([n_data, T, 1])\n",
    "Y_L = np.zeros([n_data, T, 1])\n",
    "Y_C = np.zeros([n_data, T, 1])\n",
    "X_mask = np.zeros([n_data, T], dtype=np.int16)\n",
    "i = -1\n",
    "for j, user in enumerate(dataset.keys()):\n",
    "    t, l, c = dataset[user]\n",
    "    if(len(t) <= 10):\n",
    "        continue\n",
    "    i += 1\n",
    "    t = np.array(t)\n",
    "    t[1:] = t[1:] - t[:-1]\n",
    "    t[0] = 0.0\n",
    "    l = np.array(l)\n",
    "    c = np.array(c)\n",
    "    length = len(t)\n",
    "    X_T[i][:length-1] = (t[:-1, np.newaxis])\n",
    "    X_L[i][:length-1] = (l[:-1, np.newaxis])\n",
    "    X_C[i][:length-1] = (c[:-1, np.newaxis])\n",
    "    Y_T[i][:length-1] = (t[1:, np.newaxis])\n",
    "    Y_L[i][:length-1] = (l[1:, np.newaxis])\n",
    "    Y_C[i][:length-1] = (c[1:, np.newaxis])\n",
    "    X_mask[i][:length-1] = 1\n",
    "X_T /= scale_param\n",
    "Y_T /= scale_param\n",
    "X_C /= scale_param\n",
    "Y_C /= scale_param\n",
    "n_train = n_data * 80 // 100\n",
    "n_test = n_data - n_train\n",
    "X_T_train = X_T[:n_train]\n",
    "X_L_train = X_L[:n_train]\n",
    "X_C_train = X_C[:n_train]\n",
    "X_mask_train = X_mask[:n_train]\n",
    "X_T_test = X_T[n_train:]\n",
    "X_L_test = X_L[n_train:]\n",
    "X_C_test = X_C[n_train:]\n",
    "X_mask_test = X_mask[n_train:]\n",
    "\n",
    "Y_T_train = Y_T[:n_train]\n",
    "Y_L_train = Y_L[:n_train]\n",
    "Y_C_train = Y_C[:n_train]\n",
    "Y_T_test = Y_T[n_train:]\n",
    "Y_L_test = Y_L[n_train:]\n",
    "Y_C_test = Y_C[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "print(X_C[k])\n",
    "plt.plot(X_C[k])\n",
    "# plt.plot(Y_T[k])\n",
    "plt.plot(X_mask[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    logitz = tf.log(tf.maximum(epsilon,z)) - tf.log(tf.maximum(epsilon,1 - z))\n",
    "    return logitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the recurrent cell  designed to predict churn\n",
    "class ChurnRNNCell(tf.contrib.rnn.RNNCell):    \n",
    "    def __init__(self, n_h, n_phi_prior, n_phi_encoder, n_phi_z_decoder, n_phi_h_decoder):\n",
    "        self.n_h = n_h\n",
    "        self.n_phi_prior = n_phi_prior\n",
    "        self.n_phi_encoder = n_phi_encoder\n",
    "        self.n_phi_z_decoder = n_phi_z_decoder\n",
    "        self.n_phi_h_decoder = n_phi_h_decoder\n",
    "        self.lstm = tf.contrib.rnn.LSTMCell(self.n_h, state_is_tuple=True)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return (self.n_h,self.n_h)\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return (1, 1, 1, 1, 1, self.n_h, 1, 1, 1, 1)\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        c = tf.zeros(shape=[batch_size, self.n_h], dtype=dtype)\n",
    "        h = tf.zeros(shape=[batch_size, self.n_h], dtype=dtype)\n",
    "        state_tupple = tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "        return state_tupple\n",
    "    \n",
    "    def predict_x(self, mu, sigma, phi_h_decoder, n_sampling):\n",
    "        x_predicted = 0\n",
    "        for i in range(n_sampling):\n",
    "            epsilon_sampling = tf.random_normal(tf.shape(mu), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "            z_sampling = tf.multiply(epsilon_sampling, sigma) + mu\n",
    "            with tf.variable_scope(\"Decoder\"):\n",
    "                with tf.variable_scope(\"Phi_z\"):\n",
    "                    phi_z_decoder_sampling = tf.layers.dense(z_sampling,\n",
    "                                                             self.n_phi_z_decoder,\n",
    "                                                             name='layer1',\n",
    "                                                             activation=tf.nn.relu, \n",
    "                                                             reuse=True)\n",
    "                with tf.variable_scope(\"Lambda_x\"):\n",
    "                    lmbda_sampling = tf.layers.dense(tf.concat([phi_h_decoder, phi_z_decoder_sampling], axis=1),\n",
    "                                                     1,\n",
    "                                                     name='layer1',\n",
    "                                                     activation=tf.nn.softplus, \n",
    "                                                     reuse=True)            \n",
    "            with tf.variable_scope(\"X\"):\n",
    "                x_predicted += (np.log(2)/lmbda_sampling)\n",
    "#                 x_predicted += tf.random_gamma(alpha=1, beta=lmbda_sampling, dtype=tf.float32, shape=[])\n",
    "        x_predicted = x_predicted / n_sampling\n",
    "        return x_predicted\n",
    "\n",
    "    def predict_f(self, mu, sigma, phi_h_decoder, n_sampling):\n",
    "        f_predicted = 0\n",
    "        for i in range(n_sampling):\n",
    "            epsilon_sampling = tf.random_normal(tf.shape(mu), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "            z_sampling = tf.multiply(epsilon_sampling, sigma) + mu\n",
    "            with tf.variable_scope(\"Decoder\"):\n",
    "                with tf.variable_scope(\"Phi_z\"):\n",
    "                    phi_z_decoder_sampling = tf.layers.dense(z_sampling,\n",
    "                                                             self.n_phi_z_decoder,\n",
    "                                                             name='layer1',\n",
    "                                                             activation=tf.nn.relu, \n",
    "                                                             reuse=True)\n",
    "                with tf.variable_scope(\"Lambda_f\"):\n",
    "                    lmbda_sampling = tf.layers.dense(tf.concat([phi_h_decoder, phi_z_decoder_sampling], axis=1),\n",
    "                                                     1,\n",
    "                                                     name='layer1',\n",
    "                                                     activation=tf.nn.softplus, \n",
    "                                                     reuse=True)            \n",
    "            with tf.variable_scope(\"F\"):\n",
    "                f_predicted += tf.random_poisson(lmbda_sampling, dtype=tf.float32, shape=[])\n",
    "        f_predicted = f_predicted / n_sampling\n",
    "        return f_predicted\n",
    "    \n",
    "    def __call__(self, xfz, state, scope=None):    \n",
    "        c, h = state\n",
    "        # shape of xfz is [batch_size * (2 + extra_feature_dim)]\n",
    "        x = xfz[:, 0:1]\n",
    "        f = xfz[:, 1:2]\n",
    "        xhf = tf.concat([x, h, f], axis=1, name=\"xhf\")\n",
    "        with tf.variable_scope(\"Encoder\"):\n",
    "            with tf.variable_scope(\"Hidden\"):\n",
    "                phi_encoder = tf.layers.dense(xhf, self.n_phi_encoder, activation=tf.nn.relu, name='layer1')\n",
    "            with tf.variable_scope(\"Mu\"):\n",
    "                mu_encoder = tf.layers.dense(phi_encoder, 1, name='layer1')\n",
    "            with tf.variable_scope(\"Sigma\"):\n",
    "                sigma_encoder = tf.layers.dense(phi_encoder, 1, activation=tf.nn.softplus, name='layer1')\n",
    "                \n",
    "        with tf.variable_scope(\"Prior\"):\n",
    "            with tf.variable_scope(\"Hidden\"):\n",
    "                phi_prior = tf.layers.dense(h, self.n_phi_prior, activation=tf.nn.relu, name='layer1')\n",
    "            with tf.variable_scope(\"Mu\"):\n",
    "                mu_prior = tf.layers.dense(phi_prior, 1, name='layer1')\n",
    "            with tf.variable_scope(\"Sigma\"):\n",
    "                sigma_prior = tf.layers.dense(phi_prior, 1, activation=tf.nn.softplus, name='layer1')\n",
    "\n",
    "        epsilon = tf.random_normal(tf.shape(mu_encoder), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "        z = tf.multiply(epsilon, sigma_encoder) + mu_encoder\n",
    "\n",
    "        with tf.variable_scope(\"Decoder\"):\n",
    "            with tf.variable_scope(\"Phi_h\"):\n",
    "                phi_h_decoder = tf.layers.dense(h, self.n_phi_h_decoder, activation=tf.nn.relu, name='layer1')\n",
    "            with tf.variable_scope(\"Phi_z\"):\n",
    "                phi_z_decoder = tf.layers.dense(z, self.n_phi_z_decoder, activation=tf.nn.relu, name='layer1')\n",
    "            with tf.variable_scope(\"Lambda_x\"):\n",
    "                lmbda_x = tf.layers.dense(tf.concat(values=(phi_h_decoder, phi_z_decoder), axis=1),\n",
    "                                        1, activation=tf.nn.softplus, name='layer1')\n",
    "            with tf.variable_scope(\"Lambda_f\"):\n",
    "                lmbda_f = tf.layers.dense(tf.concat(values=(phi_h_decoder, phi_z_decoder), axis=1),\n",
    "                        1, activation=tf.nn.softplus, name='layer1')\n",
    "        x_predicted = self.predict_x(mu_encoder, sigma_encoder, phi_h_decoder, n_sampling)\n",
    "        f_predicted = self.predict_f(mu_encoder, sigma_encoder, phi_h_decoder, n_sampling)\n",
    "        # TODO        f_predicted = 0\n",
    "        xfz_withz = tf.concat([x, f, z], axis=1)\n",
    "        lstm_state = tf.contrib.rnn.LSTMStateTuple(c, h)\n",
    "        output, state_new = self.lstm(xfz_withz, lstm_state)     # return state or state_new??\n",
    "        return (lmbda_x, lmbda_f, z, mu_encoder, sigma_encoder, h, mu_prior, sigma_prior, x_predicted, f_predicted), state_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, T, 1], name=\"X\")\n",
    "F = tf.placeholder(dtype=tf.float32, shape=[None, T, 1], name=\"F\")\n",
    "Z = tf.zeros(shape=[tf.shape(X)[0], T, 1], name=\"Z\")\n",
    "mask = tf.placeholder(dtype=tf.int32, shape=[None, T])\n",
    "YT = tf.placeholder(dtype=tf.float32, shape=[None, T, 1], name=\"YT\")\n",
    "YC = tf.placeholder(dtype=tf.float32, shape=[None, T, 1], name=\"YC\")\n",
    "YL = tf.placeholder(dtype=tf.float32, shape=[None, T, 1], name=\"YL\")\n",
    "\n",
    "XFZ = tf.concat([X, F, Z], axis=2, name=\"XFZ\")\n",
    "def length(mask):\n",
    "    return tf.reduce_sum(mask, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = ChurnRNNCell(n_h, n_phi_prior, n_phi_encoder, n_phi_z_decoder, n_phi_h_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output, last_state = tf.nn.dynamic_rnn(cell, XFZ, sequence_length=length(mask), dtype=tf.float32)\n",
    "lmbda_x_pred = output[0]\n",
    "lmbda_f_pred = output[1]\n",
    "z_pred = output[2]\n",
    "mu_encoder_pred = output[3]\n",
    "sigma_encoder_pred = output[4]\n",
    "h_pred = output[5]\n",
    "mu_prior_pred = output[6]\n",
    "sigma_prior_pred = output[7]\n",
    "x_pred = output[8]\n",
    "f_pred = output[9]\n",
    "z_pred_sigmoid = tf.nn.sigmoid(z_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_mre(x_pred, y, mask):\n",
    "    mre = tf.abs(x_pred[:, :, 0] - y[:, :, 0])/y[:, :, 0]\n",
    "    mre = tf.where(tf.is_nan(mre), tf.zeros_like(mre), mre)\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    mre = tf.reduce_sum(mre, axis=1)\n",
    "    mre = tf.reduce_sum(mre, axis=0)\n",
    "    mre = mre / ll\n",
    "    return mre\n",
    "\n",
    "def prediction_mse(x_pred, y, mask):\n",
    "    mse = tf.square(x_pred[:, :, 0] - y[:, :, 0])\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    mse = tf.reduce_sum(mse, axis=1)\n",
    "    mse = mse / len_mask\n",
    "    mse = tf.reduce_mean(mse, axis=0)\n",
    "    return mse\n",
    "\n",
    "def prediction_mse2(x_pred, y, mask):\n",
    "    mse = tf.square(x_pred[:, :, 0] - y[:, :, 0])\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    mse = tf.reduce_sum(mse, axis=1)\n",
    "    mse = tf.reduce_sum(mse, axis=0)\n",
    "    mse = mse / ll\n",
    "#     mse = tf.reduce_mean(mse, axis=0)\n",
    "    return mse\n",
    "def prediction_mae(x_pred, y, mask):\n",
    "    mae = tf.abs(x_pred[:, :, 0] - y[:, :, 0])\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    mae = tf.reduce_sum(mae, axis=1)\n",
    "    mae = tf.reduce_sum(mae, axis=0)\n",
    "    mae = mae / ll\n",
    "    return mae\n",
    "\n",
    "def time_reconstruction_loss(lmbda_x_pred, y, mask):\n",
    "    lmbda_x_pred_ = lmbda_x_pred[:, :, 0]\n",
    "    y_ = y[:, :, 0]\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    rl = tf.log(tf.maximum(epsilon,lmbda_x_pred_)) - tf.multiply(lmbda_x_pred_, y_)\n",
    "    rl *= tf.cast(mask, dtype=tf.float32)\n",
    "    rl = tf.reduce_sum(rl, axis=1)\n",
    "    rl = tf.reduce_sum(rl, axis=0)\n",
    "    rl /= ll\n",
    "#     rl /= len_mask\n",
    "#     rl = tf.reduce_mean(rl, axis=0)\n",
    "    return rl\n",
    "\n",
    "def mark_reconstruction_loss(lmbda_f, f, mask):\n",
    "    lmbda_f_pred_ = lmbda_f_pred[:, :, 0]\n",
    "    f_ = f[:, :, 0]\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    rl = tf.multiply(tf.log(tf.maximum(epsilon,lmbda_f_pred_)), f_) - lmbda_f_pred_\n",
    "    rl *= tf.cast(mask, dtype=tf.float32)\n",
    "    rl = tf.reduce_sum(rl, axis=1)\n",
    "    rl = tf.reduce_sum(rl, axis=0)\n",
    "    rl /= ll\n",
    "#     rl /= len_mask\n",
    "#     rl = tf.reduce_mean(rl, axis=0)\n",
    "    return rl\n",
    "\n",
    "def time_KL_loss(z_pred, mu_encoder_pred, sigma_encoder_pred, mu_prior_pred, sigma_prior_pred, mask, use_prior=False):\n",
    "    z_pred_ = z_pred[:, :, 0]\n",
    "    mu_encoder_pred_ = mu_encoder_pred[:, :, 0]\n",
    "    sigma_encoder_pred_ = sigma_encoder_pred[:, :, 0]\n",
    "    mu_prior_pred_ = mu_prior_pred[:, :, 0]\n",
    "    sigma_prior_pred_ = sigma_prior_pred[:, :, 0]\n",
    "    if(use_prior):\n",
    "        kl = (tf.log(tf.maximum(epsilon, sigma_encoder_pred_)) - tf.log(tf.maximum(epsilon, sigma_prior_pred_)) + \n",
    "             (tf.square(sigma_encoder_pred_) + tf.square(mu_encoder_pred_ - mu_prior_pred_)) / (2 * tf.square(sigma_prior_pred_)) - 0.5)\n",
    "        kl = tf.where(tf.is_nan(kl), tf.zeros_like(kl), kl)\n",
    "    else:\n",
    "        kl = (tf.log(tf.maximum(epsilon, sigma_encoder_pred_)) - tf.log(tf.maximum(epsilon, sigma0)) + \n",
    "             (tf.square(sigma_encoder_pred_) + tf.square(mu_encoder_pred_ - mu0)) / (2 * tf.square(sigma0)) - 0.5)\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    kl = kl * tf.cast(mask, dtype=tf.float32)\n",
    "    kl = tf.reduce_sum(kl, axis=1)\n",
    "    kl = tf.reduce_sum(kl, axis=0)\n",
    "    kl /= ll\n",
    "#     kl /= len_mask\n",
    "#     kl = tf.reduce_mean(kl)\n",
    "    return kl\n",
    "\n",
    "TRL = time_reconstruction_loss(lmbda_x_pred, YT, mask)\n",
    "TML = mark_reconstruction_loss(lmbda_f_pred, YC, mask)\n",
    "# TKL = time_KL_loss(z_pred, mu_encoder_pred, sigma_encoder_pred, mu_prior_pred, sigma_prior_pred, mask, use_prior=False)\n",
    "TKL = time_KL_loss(z_pred, mu_encoder_pred, sigma_encoder_pred, mu_prior_pred, sigma_prior_pred, mask, use_prior=Use_Prior)\n",
    "loss =  TKL - TRL - TML # Remove 0.05\n",
    "MSE_x = prediction_mse(x_pred, YT, mask)\n",
    "MSE_x2 = prediction_mse2(x_pred, YT, mask)\n",
    "MAE_x = prediction_mae(x_pred, YT, mask)\n",
    "MRE_x = prediction_mre(x_pred, YT, mask)\n",
    "\n",
    "MSE_f = prediction_mse(f_pred, YC, mask)\n",
    "MSE_f2 = prediction_mse2(f_pred, YC, mask)\n",
    "MAE_f = prediction_mae(f_pred, YC, mask)\n",
    "MRE_f = prediction_mre(f_pred, YC, mask)\n",
    "\n",
    "lr = tf.placeholder_with_default(0.001, shape=[])\n",
    "# train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "train_operation = tf.train.RMSPropOptimizer(lr).minimize(loss)\n",
    "train_operation_mse = tf.train.AdamOptimizer(lr).minimize(MSE_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "ses = tf.InteractiveSession(config=config)\n",
    "ses.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict={X:X_T_test, YT:Y_T_test, YC:Y_C_test, mask:X_mask_test, F:X_C_test}\n",
    "z_pred_sigmoid_values, f_pred_values, x_pred_values, lmbda_x_pred_values, lmbda_f_pred_values, z_pred_values, mu_pred_values = ses.run([z_pred_sigmoid, f_pred, x_pred, lmbda_x_pred, lmbda_f_pred, z_pred, mu_encoder_pred], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [ses.run(logit(z)) for z in z_pred_values[30]]\n",
    "print(temp)\n",
    "plt.plot(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses.run(TKL, feed_dict={X:X_T_train, YT:Y_T_train, YC:Y_C_train, mask:X_mask_train, F:X_L_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "plt.plot(x_pred_values[k, :, 0], 'r')\n",
    "# plt.plot(lmbda_x_pred_values[k, :, 0] / 10, 'bo')\n",
    "plt.plot(z_pred_sigmoid_values[k, :, 0], \"g\")\n",
    "# plt.plot(mu_pred_values[k, :, 0], label=\"g\")\n",
    "\n",
    "# plt.plot(X_T[0])\n",
    "plt.plot(Y_T_test[k], 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "plt.plot(f_pred_values[k, :, 0], 'r')\n",
    "# plt.plot(lmbda_pred_values[k, :, 0] / 10, 'bo')\n",
    "# plt.plot(z_pred_values[k, :, 0], label=\"go\")\n",
    "# plt.plot(mu_pred_values[k, :, 0], label=\"g\")\n",
    "\n",
    "# plt.plot(X_T[0])\n",
    "plt.plot(Y_C_test[k], 'black')\n",
    "plt.plot(X_mask_test[k], 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_T_train_mean = np.mean(Y_T_train, axis=1, keepdims=False)\n",
    "Y_T_train_mean = np.mean(Y_T_train, axis=0, keepdims=False)\n",
    "YY = (Y_T_test - Y_T_train_mean) ** 2\n",
    "YY = YY[:, :, 0]\n",
    "YS = np.sum(YY, axis=1)\n",
    "msk = np.sum(X_mask_test, axis=1)\n",
    "YS /= msk\n",
    "lower_bound_time_mse = np.mean(YS)\n",
    "print(lower_bound_time_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sum(Y_T_train)\n",
    "b = np.sum(X_mask_train)\n",
    "avg = a/b\n",
    "tt = Y_T_test\n",
    "print(tt.shape)\n",
    "for u in range(tt.shape[0]):\n",
    "    for d in range(tt.shape[1]):\n",
    "        if(X_mask_test[u][d]>0):\n",
    "            tt[u][d] =  (tt[u][d] - avg) ** 2\n",
    "ss = np.sum(tt)\n",
    "mm = np.sum(X_mask_test)\n",
    "print(ss/mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_C_train_mean = np.mean(Y_C_train, axis=1, keepdims=False)\n",
    "Y_C_train_mean = np.mean(Y_C_train, axis=0, keepdims=False)\n",
    "YY = (Y_C_test - Y_C_train_mean) ** 2\n",
    "YY = YY[:, :, 0]\n",
    "YS = np.sum(YY, axis=1)\n",
    "msk = np.sum(X_mask_test, axis=1)\n",
    "YS /= msk\n",
    "lower_bound_mark_mse = np.mean(YS)\n",
    "print(lower_bound_mark_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mse = {\"Train\":[], \"Test\":[]}\n",
    "time_mse2 = {\"Train\":[], \"Test\":[]}\n",
    "time_mae = {\"Train\":[], \"Test\":[]}\n",
    "time_mre = {\"Train\":[], \"Test\":[]}\n",
    "total_loss = {\"Train\":[], \"Test\":[]}\n",
    "mark_mse = {\"Train\":[], \"Test\":[]}\n",
    "mark_mse2 = {\"Train\":[], \"Test\":[]}\n",
    "mark_mae = {\"Train\":[], \"Test\":[]}\n",
    "mark_mre = {\"Train\":[], \"Test\":[]}\n",
    "kl = {\"Train\":[], \"Test\":[]}\n",
    "mark_rl = {\"Train\":[], \"Test\":[]}\n",
    "time_rl = {\"Train\":[], \"Test\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    feed_dict={X:X_T_train, YT:Y_T_train, YC:Y_C_train, mask:X_mask_train, F:X_C_train}\n",
    "    len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "    ll = tf.reduce_sum(len_mask)\n",
    "    r = ses.run([ll], feed_dict=feed_dict)\n",
    "    print(r)\n",
    "    l, mx, mx2, maex, mrx, mf, mf2, maef,mrf, kl_, time_rl_, mark_rl_  = ses.run(\n",
    "        [loss, MSE_x, MSE_x2, MAE_x, MRE_x, MSE_f, MSE_f2, MAE_f, MRE_f, TKL, -TRL, -TML], feed_dict=feed_dict)\n",
    "    time_mse[\"Train\"].append(mx)\n",
    "    time_mse2[\"Train\"].append(mx2)\n",
    "    time_mae[\"Train\"].append(maex)\n",
    "    time_mre[\"Train\"].append(mrx)\n",
    "    \n",
    "    mark_mse[\"Train\"].append(mf)\n",
    "    mark_mse2[\"Train\"].append(mf2)\n",
    "    mark_mae[\"Train\"].append(maef)\n",
    "    mark_mre[\"Train\"].append(mrf)\n",
    "    \n",
    "    total_loss[\"Train\"].append(l)\n",
    "    kl[\"Train\"].append(kl_)\n",
    "    mark_rl[\"Train\"].append(mark_rl_)\n",
    "    time_rl[\"Train\"].append(time_rl_)\n",
    "    print(\"Epoch = {}\".format(epoch))\n",
    "    print(\n",
    "        \"train loss : \",  l, \n",
    "        \"train time mse : \", mx,\n",
    "        \"train time mse2 : \", mx2,\n",
    "        \"train time mae : \", maex, \n",
    "        \"train time mre : \", mrx, \n",
    "        \"train F mse : \", mf,\n",
    "        \"train F mse2 : \", mf2,\n",
    "        \"train F mae : \", maef,\n",
    "        \"train F mre : \", mrf,\n",
    "    )\n",
    "    \n",
    "    feed_dict={X:X_T_test, YT:Y_T_test, YC:Y_C_test, mask:X_mask_test, F:X_C_test}\n",
    "    l, mx, mx2, maex, mrx, mf, mf2, maef,mrf, kl_, time_rl_, mark_rl_  = ses.run(\n",
    "        [loss, MSE_x, MSE_x2, MAE_x, MRE_x, MSE_f, MSE_f2, MAE_f, MRE_f, TKL, -TRL, -TML], feed_dict=feed_dict)\n",
    "    print(\n",
    "        \"test loss : \",  l, \n",
    "        \"test time mse : \", mx,\n",
    "        \"test time mse2 : \", mx2,\n",
    "        \"test time mae : \", maex, \n",
    "        \"test time mre : \", mrx, \n",
    "        \"test F mse : \", mf,\n",
    "        \"test F mse2 : \", mf2,\n",
    "        \"test F mae : \", maef,\n",
    "        \"test F mre : \", mrf,\n",
    "    )\n",
    "    time_mse[\"Test\"].append(mx)\n",
    "    time_mse2[\"Test\"].append(mx2)\n",
    "    time_mae[\"Test\"].append(maex)\n",
    "    time_mre[\"Test\"].append(mrx)\n",
    "    \n",
    "    mark_mse[\"Test\"].append(mf)\n",
    "    mark_mse2[\"Test\"].append(mf2)\n",
    "    mark_mae[\"Test\"].append(maef)\n",
    "    mark_mre[\"Test\"].append(mrf)\n",
    "    total_loss[\"Test\"].append(l)\n",
    "    kl[\"Test\"].append(kl_)\n",
    "    mark_rl[\"Test\"].append(mark_rl_)\n",
    "    time_rl[\"Test\"].append(time_rl_)\n",
    "    \n",
    "    print()\n",
    "    def get_lr(epoch):\n",
    "        return learning_rate\n",
    "        if(epoch < 5):\n",
    "            return 0.1\n",
    "        if(epoch < 10):\n",
    "            return 0.05\n",
    "        if(epoch < 15):\n",
    "            return 0.025\n",
    "        if(epoch < 20):\n",
    "            return 0.01\n",
    "        if(epoch < 30):\n",
    "            return 0.005\n",
    "        return 0.001\n",
    "    feed_dict={X:X_T_train, YT:Y_T_train, YC:Y_C_train, mask:X_mask_train, F:X_C_train, lr:get_lr(epoch)}\n",
    "    _ = ses.run(train_operation, feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.yscale(\"log\")\n",
    "plot_target = time_mre\n",
    "plt.title(\"Predicted Mark MSE\")\n",
    "plt.plot(plot_target[\"Train\"], 'g', label=\"Train\")\n",
    "plt.plot(plot_target[\"Test\"], 'r', label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "result_dict[\"Time MSE\"] = time_mse\n",
    "result_dict[\"Mark MSE\"] = mark_mse\n",
    "result_dict[\"Time Reconstruction Loss\"] = time_rl\n",
    "result_dict[\"Mark Reconstruction Loss\"] = mark_rl\n",
    "result_dict[\"Loss\"] = total_loss\n",
    "result_dict[\"KL\"] = kl\n",
    "result_dict[\"Session Length\"] = session_length\n",
    "result_dict[\"Dataset Name\"] = dataset_name\n",
    "result_dict[\"Lower Bound Time MSE\"] = lower_bound_time_mse\n",
    "result_dict[\"Lower Bound Mark MSE\"] = lower_bound_mark_mse\n",
    "result_dict[\"Use Prior\"] = Use_Prior\n",
    "\n",
    "np.save(\"Result/Gaussian/{0}_{1}\".format(dataset_name, session_length), result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gauss = np.load(\"Result/Gaussian/tianchi_24.0.npy\").item()\n",
    "logit = np.load(\"Result/Logit_Normal/tianchi_24.0.npy\").item()\n",
    "logit['Lower Bound Mark MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_keys(\n",
    "# ['KL', 'Lower Bound Time MSE', 'Dataset Name', 'Time MSE', 'Session Length', 'Loss', \n",
    "# 'Time Reconstruction Loss', 'Mark Reconstruction Loss', 'Mark MSE', 'Lower Bound Mark MSE'])\n",
    "plot_target = 'Session Length'\n",
    "# plt.title(\"Predicted Mark MSE\")\n",
    "plt.plot(logit[plot_target][\"Test\"], 'g', label=\"logit\")\n",
    "plt.plot(gauss[plot_target][\"Test\"], 'r', label=\"gauss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train loss :  -24.221628 train time mse :  419.20953 train F mse :  0.0002365092\n",
    "test loss :  -24.243528 test time mse :  397.769 test F mse :  0.00027706148\n",
    "            \n",
    "Epoch = 69\n",
    "train loss :  -27.78592 train time mse :  0.7239679 train F mse :  1.15438315e-05\n",
    "test loss :  -27.805645 test time mse :  0.68592244 test F mse :  1.1152147e-05\n",
    "\n",
    "#BEST\n",
    "test loss :  -28.098305 test time mse :  0.48489192 test F mse :  2.2147236e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.1152147e-05\n",
    "a*3600*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_zps = np.zeros([990, 95, 1])\n",
    "for epoch in range(n_epoch):\n",
    "    feed_dict={X:X_T_train, YT:Y_T_train, YC:Y_C_train, mask:X_mask_train, F:X_C_train}\n",
    "    zps,l, mx, mf, kl_, time_rl_, mark_rl_  = ses.run([mu_encoder_pred, loss, MSE_x, MSE_f, TKL, -TRL, -TML], feed_dict=feed_dict)\n",
    "    tot_zps += zps\n",
    "    print(tot_zps.shape)\n",
    "    time_mse[\"Train\"].append(mx)\n",
    "    mark_mse[\"Train\"].append(mf)\n",
    "    total_loss[\"Train\"].append(l)\n",
    "    kl[\"Train\"].append(kl_)\n",
    "    mark_rl[\"Train\"].append(mark_rl_)\n",
    "    time_rl[\"Train\"].append(time_rl_)\n",
    "    print(\"Epoch = {}\".format(epoch))\n",
    "    print(\"train loss : \",  l, \"train time mse : \", mx, \"train F mse : \", mf)\n",
    "    print()\n",
    "    def get_lr(epoch):\n",
    "        return learning_rate\n",
    "        if(epoch < 5):\n",
    "            return 0.1\n",
    "        if(epoch < 10):\n",
    "            return 0.05\n",
    "        if(epoch < 15):\n",
    "            return 0.025\n",
    "        if(epoch < 20):\n",
    "            return 0.01\n",
    "        if(epoch < 30):\n",
    "            return 0.005\n",
    "        return 0.001\n",
    "    feed_dict={X:X_T_train, YT:Y_T_train, YC:Y_C_train, mask:X_mask_train, F:X_C_train, lr:get_lr(epoch)}\n",
    "    _ = ses.run(train_operation, feed_dict=feed_dict)\n",
    "\n",
    "tot_zps = tot_zps/n_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = X_mask_train\n",
    "print(sum(X_mask_train[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_percentile_zs(predicted_zs, mask):\n",
    "    number_of_elements = sum(mask)\n",
    "    bin_length = number_of_elements/10\n",
    "    binned_predicted_zs = {}\n",
    "    for i in range(number_of_elements):\n",
    "        bin_index = math.floor((i+1)/bin_length)\n",
    "        if bin_index >9:\n",
    "            bin_index = 9\n",
    "        try:\n",
    "            binned_predicted_zs[bin_index].append(predicted_zs[i])\n",
    "        except:\n",
    "            binned_predicted_zs[bin_index]=[predicted_zs[i]]\n",
    "    average_predicted_z_list = np.zeros([10,1])\n",
    "    for key in binned_predicted_zs.keys():\n",
    "        s = sum(binned_predicted_zs[key])[0]\n",
    "        l = len(binned_predicted_zs[key])\n",
    "        m = s/l\n",
    "        average_predicted_z_list[key]= m\n",
    "    return average_predicted_z_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users,_,_= tot_zps.shape\n",
    "total_zs_list = np.zeros([10,1])\n",
    "for u in range(users):\n",
    "    total_zs_list += get_percentile_zs(tot_zps[u], X_mask_train[u])\n",
    "total_zs_list = total_zs_list/users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_zs_list[1:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_zs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "ses = tf.InteractiveSession(config=config)\n",
    "ses.run(tf.global_variables_initializer())\n",
    "a = np.array([1,2,0])\n",
    "b = np.array([1.5, 2.5, 0])\n",
    "msk = np.array([1,1,0])\n",
    "mre = tf.abs(a - b)/a\n",
    "mre = mre * msk\n",
    "res = tf.where(msk==0,tf.zeros_like(mre), mre)\n",
    "print(ses.run([res]))\n",
    "#     len_mask = tf.cast(length(mask), dtype=tf.float32)\n",
    "#     mse = tf.reduce_sum(mre, axis=1)\n",
    "#     mse = mse / len_mask\n",
    "#     mse = tf.reduce_mean(mse, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"A,\",1,\n",
    "    \"B,\",2\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.mean(mses, axis=0)\n",
    "y_u = x + np.std(mses, axis=0)\n",
    "y_d = x - np.std(mses, axis=0)\n",
    "f = open(\"datatttt.txt\", 'w')\n",
    "for i in range(70):\n",
    "    f.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(i+1,x[i], y_u[i], y_d[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from Network import Network\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "'''\n",
    "Load data\n",
    "'''\n",
    "# ds_names = ['lastfm', 'tianchi', 'foursquare', 'iptv']\n",
    "ds_names = ['iptv']\n",
    "sess_lengths = [1.0, 2.0, 4.0, 6.0, 8.0, 12.0, 24.0]\n",
    "for name in ds_names: \n",
    "    for length in sess_lengths:\n",
    "        dataset_name = name\n",
    "        session_length = length\n",
    "        data_base_path = \"../../../data/\"\n",
    "        data_path = '{0}user_session_dictionary_{1}_{2}.npy'.format(data_base_path, dataset_name, session_length)\n",
    "\n",
    "        data_settings = {\n",
    "            \"data_path\": data_path,\n",
    "            \"dataset_name\": dataset_name,\n",
    "            'session_length': session_length,\n",
    "            \"scale_param\": 100,\n",
    "        }\n",
    "        dl = DataLoader(data_settings)\n",
    "        data = dl.load_data()\n",
    "\n",
    "        print(\"Data Loaded ....\")\n",
    "        print(\"Data Statistics are:\")\n",
    "        print(str(dl))\n",
    "\n",
    "        network_settings = {\n",
    "            'n_sampling': 90,\n",
    "            'n_h': 60,\n",
    "            'n_phi_prior': 10,\n",
    "            'n_phi_encoder': 10,\n",
    "            'n_phi_z_decoder': 10,\n",
    "            'n_phi_h_decoder': 10,\n",
    "            'mu0': 0,\n",
    "            'sigma0': 1.8,\n",
    "            'n_epoch': 70,\n",
    "            'learning_rate': 0.03,\n",
    "            'epsilon': 1e-12,\n",
    "            'use_prior': True,\n",
    "            'len_seq': data['T']\n",
    "        }\n",
    "        run_dur = 0\n",
    "        for i in range(1):\n",
    "            tf.reset_default_graph()\n",
    "            print(\"\\033[95m RUN:{0}, Prev Run Duration is: {1}\".format(i, run_dur))\n",
    "            print('\\033[92m')\n",
    "            start=datetime.now()\n",
    "            network = Network(network_settings)\n",
    "            print(\"Network Created ....\")\n",
    "            print(\"Network Info is:\")\n",
    "            print(str(network))\n",
    "            sess = tf.InteractiveSession(config=config)\n",
    "            network(data, sess, i)\n",
    "            end=datetime.now()\n",
    "            run_dur = end-start\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
